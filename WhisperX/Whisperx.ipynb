{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305e880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -qq git+https://github.com/openai/whisper.git \n",
    "#!pip install --force-reinstall git+https://github.com/mattiaswickberg/whisperx.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60179125",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -qq torch==1.8.1 torchvision==0.9.1 torchaudio==0.9.0 torchtext==0.8.0\n",
    "#!pip install -qq speechbrain==0.5.12\n",
    "#!pip install torch==1.12.1+cu116 torchvision==0.13.1+cu116 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "#!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5d7cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess #if stripping audio from video file\n",
    "import datetime #to print time of start and end of analysis\n",
    "#import torch\n",
    "#import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9c848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "f = open('../credentials.json')\n",
    "credentials = json.load(f)\n",
    "hf_token = credentials[\"hf_token\"]\n",
    "wav2vec_model = credentials[\"wav2vec_large\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea38854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def speakers(file):\n",
    "    speakers = re.findall(\"n_(\\d+).\", file)\n",
    "    if len(speakers) > 0:\n",
    "        return int(speakers[0])\n",
    "    else: \n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58fc92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolate_audio(file):\n",
    "    wav_file = file + '.wav'\n",
    "    subprocess.call(['ffmpeg', '-i', file, wav_file, '-y'])\n",
    "    return wav_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37919cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(wav_file, num_speakers):\n",
    "    !whisperx {wav_file} --model large --language sv --output_type txt --hf_token {hf_token} --min_speakers {num_speakers} --vad_filter --align_model {wav2vec_model}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b6c970-7781-43e4-a086-3e857ec05ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "def file_length(file):\n",
    "    # Load the audio file using pydub\n",
    "    audio_file = AudioSegment.from_file(file, format=\"wav\")\n",
    "\n",
    "    # Get the duration of the audio file in milliseconds\n",
    "    duration_ms = len(audio_file)\n",
    "\n",
    "    # Convert the duration from milliseconds to seconds\n",
    "    duration = datetime.timedelta(milliseconds=duration_ms)\n",
    "    duration_str = str(duration)\n",
    "    \n",
    "    return duration_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8cd130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_file(text):\n",
    "    with open('log_file.txt', 'a') as file:\n",
    "        s = \"\".join(text)\n",
    "        file.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed332ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def iterate():\n",
    "    try:\n",
    "        \n",
    "        for filename in os.listdir(\"/mimer/NOBACKUP/groups/stls/Data\"):\n",
    "            if not \".ipynb\" in filename:\n",
    "                start_1 = start = datetime.datetime.now()\n",
    "                file_path = os.path.join(\"/mimer/NOBACKUP/groups/stls/Data\", filename)\n",
    "                num_speakers = speakers(file_path)\n",
    "                wav_file = isolate_audio(file_path)\n",
    "                transcribe(wav_file, num_speakers)\n",
    "                end_1 = start = datetime.datetime.now()\n",
    "                delta_1 = end_1 -  start_1\n",
    "                log_file(\"Duration of \" + filename + \"is \" + file_length(wav_file))\n",
    "                log_file(\"Transkription for \" + filename + \" was \" + str(delta_1) + '\\n')\n",
    "            \n",
    "    except Exception as e:\n",
    "            print(f'An error has occured: {e}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3cacec",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "iterate()\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "delta = end - start\n",
    "log_file(\"Runtime for whole batch was \" + str(delta) +('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fb6116-3a38-4cbe-9ea2-3483088aea21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c4e12c305e6735e6afde9f5feea71b06f5561a10f57b29b44d6b7254fd54df9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
